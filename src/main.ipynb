{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff8972b8-a5c3-4981-99c3-b0f3784ae5b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95ecee2a-1050-4892-83f7-c8cd42773eca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.optim as optim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4047a96-05f3-4833-99c8-2d28d0387a57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81448acc-9554-4a31-80fa-d881317885f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def prepare_models(num_classes):\n",
    "    from torchvision.models import resnet34, ResNet34_Weights, shufflenet_v2_x0_5, ShuffleNet_V2_X0_5_Weights\n",
    "\n",
    "    set_seed()\n",
    "\n",
    "    # Initializing student model\n",
    "    student_model = shufflenet_v2_x0_5(weights=ShuffleNet_V2_X0_5_Weights.DEFAULT)\n",
    "    student_model.fc = nn.Linear(student_model.fc.in_features, num_classes)\n",
    "\n",
    "    # Initializing teacher model\n",
    "    teacher_model = resnet34(weights=ResNet34_Weights.DEFAULT)\n",
    "    teacher_model.fc = nn.Linear(teacher_model.fc.in_features, num_classes)\n",
    "\n",
    "    return teacher_model, student_model\n",
    "\n",
    "def get_cifar100_dataloaders(batch_size=256):\n",
    "    mean = (0.5070751592371323, 0.48654887331495095, 0.4409178433670343)\n",
    "    std = (0.26733428587941854, 0.25643846292120615, 0.2761504713263903)\n",
    "    cache = '/dbfs/cache'\n",
    "\n",
    "    transform_train = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.RandomCrop(32, padding=4),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.Normalize(mean, std)\n",
    "    ])\n",
    "    transform_test = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean, std)\n",
    "    ])\n",
    "\n",
    "    # Creating datasets\n",
    "    train_set = datasets.CIFAR100(root=cache, train=True, download=True, transform=transform_train)\n",
    "    test_set = datasets.CIFAR100(root=cache, train=False, download=True, transform=transform_test)\n",
    "    \n",
    "    # Creating dataloaders\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=os.cpu_count())\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=os.cpu_count())\n",
    "\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57f49c12-382c-47c8-8020-797de790d9b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, model_path, load=False):\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.001)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "\n",
    "    epochs = 100\n",
    "    avg_losses, avg_accuracies = [], []\n",
    "\n",
    "    if os.path.exists(model_path) and load:\n",
    "        # Loading weights\n",
    "        try:\n",
    "            model.load_state_dict(torch.load(model_path))\n",
    "            print(\"Model loaded\")\n",
    "        except:\n",
    "            raise Exception(\"Model not found\")\n",
    "        \n",
    "        # Getting base accuracy\n",
    "        model.eval()\n",
    "        base_accuracy = 0\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(test_loader):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                base_accuracy += (predicted == labels).sum().item()\n",
    "\n",
    "        base_accuracy = (base_accuracy / len(test_loader.dataset)) * 100\n",
    "        avg_accuracies.append(base_accuracy)\n",
    "    else:\n",
    "        os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "        print(\"Model not found\")\n",
    "\n",
    "    # Model training\n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Testing\n",
    "        model.eval()\n",
    "        running_accuracy = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(test_loader):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                running_accuracy += (predicted == labels).sum().item()\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        avg_accuracy = (running_accuracy / len(test_loader.dataset)) * 100\n",
    "\n",
    "        avg_losses.append(avg_loss)\n",
    "        avg_accuracies.append(avg_accuracy)\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/ {epochs}]: Loss: {avg_loss:.4f} | Accuracy: {avg_accuracy:.2f}')   \n",
    "\n",
    "        if len(avg_accuracies) > 1 and avg_accuracy > max(avg_accuracies[:-1]):\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(\"Model saved\")\n",
    "        elif len(avg_accuracies) == 1:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(\"Model saved\")\n",
    "\n",
    "    return avg_losses, avg_accuracies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ce8ddcd-00f6-4d66-b8a4-2c82071b8bfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "teacher_model, student_model = prepare_models(num_classes=100)\n",
    "train_loader, test_loader = get_cifar100_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9fadaf4-9b50-4432-91bd-638aaac0ee30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_path = '/dbfs/research2/best_model.pth'\n",
    "avg_losses, avg_accuracies = train(teacher_model, train_loader, test_loader, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d95c263-2f59-4077-ac6b-ab5913f2779d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def train_student_with_kd(student, teacher, train_loader, test_loader, device, epochs=30):\n",
    "    \"\"\"Train student with knowledge distillation\"\"\"\n",
    "    kd_criterion = KnowledgeDistillationLoss(alpha=0.7, temperature=4.0)\n",
    "    optimizer = torch.optim.Adam(student.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    \n",
    "    teacher.eval()  # Teacher in eval mode\n",
    "    \n",
    "    print(\"Training student with knowledge distillation...\")\n",
    "    best_acc = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        student.train()\n",
    "        running_loss = 0.0\n",
    "        running_kd_loss = 0.0\n",
    "        running_ce_loss = 0.0\n",
    "        \n",
    "        for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Get predictions\n",
    "            with torch.no_grad():\n",
    "                teacher_logits = teacher(data)\n",
    "            student_logits = student(data)\n",
    "            \n",
    "            # Compute KD loss\n",
    "            total_loss, kd_loss, ce_loss = kd_criterion(student_logits, teacher_logits, labels)\n",
    "            \n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += total_loss.item()\n",
    "            running_kd_loss += kd_loss.item()\n",
    "            running_ce_loss += ce_loss.item()\n",
    "            \n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f'KD Epoch {epoch}, Batch {batch_idx}, Total: {total_loss.item():.4f}, '\n",
    "                      f'KD: {kd_loss.item():.4f}, CE: {ce_loss.item():.4f}')\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Validation\n",
    "        if epoch % 5 == 0:\n",
    "            acc = evaluate_model(student, test_loader, device)\n",
    "            print(f'Student Epoch {epoch}, Test Accuracy: {acc:.2f}%')\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                torch.save(student.state_dict(), 'student_kd_model.pth')\n",
    "    \n",
    "    print(f'Student KD training complete. Best accuracy: {best_acc:.2f}%')\n",
    "    return best_acc"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "main",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
